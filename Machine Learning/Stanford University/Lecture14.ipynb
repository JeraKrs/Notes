{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture14 Anomaly Detection\n",
    "\n",
    "For an dataset $\\{ x^{(1)}, \\dots, x^{(m)} \\}$, detect that is $x_{test}$ anomalous?\n",
    "\n",
    "Anomaly detection example: fraud detection, manufacturing, monitoring computer in a data center.\n",
    "\n",
    "**Gaussion distribution**: $x \\sim \\mathcal{N}(\\mu, \\sigma^2): p(x;\\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi \\sigma}}exp\\left( -\\frac{(x-\\mu)^2}{2\\sigma^2} \\right)$\n",
    "\n",
    "\n",
    "**Anomaly detection algorithm**:\n",
    "1. choose features $x_i$ that you think might be indicative of anomalous examples.\n",
    "2. fit parameters $\\mu_1, \\dots, \\mu_n, \\sigma^2_1, \\dots, \\sigma^2_n$.\n",
    "    * $\\mu_j = \\frac{1}{m}\\sum^m_{i=1}x^{(i)}_j$\n",
    "    * $\\sigma^2_j = \\frac{1}{m}\\sum^m_{i=1}(x^{(i)}_j - \\mu_j)^2$\n",
    "3. given new example x, comput $p(x) = \\prod_{j=1}^n p(x_j; \\mu_j, \\sigma^2_j) = \\prod^n_{j=1} \\frac{1}{\\sqrt{2\\pi \\sigma_j}}exp(-\\frac{(x_j-\\mu_j)^2}{2\\sigma_j^2})$, anomaly if $p(x) < \\epsilon$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm evaluation\n",
    "\n",
    "10000 good (normal) engines, 20 flawed engines (anomalous).\n",
    "\n",
    "1. Training set: 6000 good engines; CV: 2000 good engines (y=0), 10 anomalous (y=1); Test: 2000 good engines (y=0), 10 anomalous (y=1);\n",
    "2. Fit model $p(x)$ on training set $\\{x^{(1)}, \\dots, x^{(m)}$.\n",
    "3. On a cross validation/test example x, predict $y=1$ (anomaly) if $p(x) < \\epsilon$; $y=0$ (normal) if $p(x) \\geq \\epsilon$.\n",
    "4. Possible evaluation metrics, use cross validation set to choose parameter $\\epsilon$:\n",
    "    * True positive, false positive, false negative, true negative.\n",
    "    * Precision/Recall.\n",
    "    * F1-score.\n",
    "    \n",
    "    \n",
    "**Anomaly detection vs. supervised learning**\n",
    "* anomaly detection:\n",
    "    * very small number of positive examples.\n",
    "    * large number of negative examples.\n",
    "    * many different \"types\" of anomalies.\n",
    "* supervised learning\n",
    "    * large number of positive and negative examples.\n",
    "    * enough positive examples for algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate Gaussian Distribution\n",
    "\n",
    "$$p(x; \\mu, \\Sigma) = \\frac{1}{(2\\pi)^{n/2} |\\Sigma|^{1/2}} exp\\left( -\\frac{1}{2}(x-\\mu)^T\\Sigma^{-1}(x - \\mu)\\right)$$\n",
    "\n",
    "**Parameter fitting**: $\\mu=\\frac{1}{m}\\sum^m_{i=1}x^{(i)}, \\Sigma = \\frac{1}{m}\\sum^m_{i=1}(x^{(i)} - \\mu)(x^{(i)} - \\mu)^T$.\n",
    "\n",
    "\n",
    "**Original model vs. Multivariate gaussian**:\n",
    "* Original model:\n",
    "    * Manually create features to capture anomalies where $x_1, x_2$ take unusual combinations of values.\n",
    "    * Computationally cheaper.\n",
    "    * OK even if m is small.\n",
    "* Multivariate gaussianï¼š\n",
    "    * Automatically captures correlations between features.\n",
    "    * Computationally more expensive.\n",
    "    * Must have $m > n$ or else $\\Sigma$ is non-invertible."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
